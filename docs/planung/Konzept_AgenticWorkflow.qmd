---
title: "Konzept Tool zur LLM-gestützten Inhaltsanalyse"
format: pdf
---

# **Ausgangslage zur Nutzung von LLMs zur Inhaltsanalyse/qualitativem Coding in der soziologischen/sozialwissenschaftlchen Forschung**

### Potenziale für die Nutzung von LLMs

-   Massive und feingranulare Informationsgewinnung; hohe Präzision

-   Skalierbarkeit & Effizienz (Geschwindigkeit, Genauigkeit, keine "Ermüdungseffekte"

-   Zugänglichkeit & Flexibilität

-   Transparenz & Replizierbarkeit

### Risiken aktuell

-   Voreingenommenheit und Stereotypen von LLMs reproduzieren

-   Systematische, nicht-zufällige Fehler und Verzerrungen

-   Ethische & soziale Implikationen

-   Mangelndes inhaltliches Verständnis von LLMs

### Aktuelle Herausforderungen bei der Umsetzung

-   Methodologische Reflexivität & Validierung

-   Prompt-Engineering: manuelle Anpassung von Prompts notwendig, aber Prompts können auf unzählige Weisen angepasst werden, wann soll man Prompt-Engineering stoppen, wann ist Leistungsgrenze des Modells erreicht?

-   Technische Anforderungen & Kosten; Unvorhersehbares Modellverhalten

## Ansatz für diese Herausforderungen:

Farjam, M., Meyer, H., & Lohkamp, M. (2025). A Practical Guide and Case Study on How to Instruct LLMs for Automated Coding During Content Analysis. Social Science Computer Review, 0(0). <https://doi.org/10.1177/08944393251349541>

Pipeline für kontinuierliche Selbstverbesserung von Klassifikationsproblemen. Human-in-the-Loop Ansatz; menschlicher "Vermittler"; LLM in drei "Task-Rollen" aufgebrochen

Ansatz integriert verschiedene Strategien, um aktuelle Herausforderungen zu verbessern:

"Agentic Workflow": LLMs als "spezialisierte Agenten" einsetzen, um Inhaltsanalyse zu automatisieren, validieren und optimieren. Der Prozess gliedert das LLM in drei Agenten, ergänzt von einer menschlichen Kontrollinstanz:

-   Human Intermediary: Zuständig für Definition & Validierung, stellt anfängliche Anweisungen bereit, verfeinert die Prompts, basierend auf LLM-Ausgabe.

-   Instructor (LLM): Prompt-Optimierung (Meta-Prompting): Nimmt menschliche Anweisungen entgegen und formuliert diese in eine optimierte, strukturierte Prompt für de Classifier um

-   Classifier (LLM): Führt Klassifikation/eigentliche Codierungsaufgabe für jedes Dokument durch, liefert explizite Chain of Thought Begründung

-   Judge (LLM; optional): Für Konfliktlösung und Zuverlässigkeit, könnte optional aktiviert werden, wenn die Klassifizierungszuverlässigkeit niedrig ist; Judge entscheidet bei widersprüchlichen Codierungen (aus mehreren Läufen), basierend auf kohärentester CoT Begründung

**Agentic Workflow zielt darauf ab, zentrale Probleme der LLM_Nutzung zu adressieren:**

-   Mangelnde Systematik im Prompt-Engineering: Instructor nutzt Meta-Prmpting (LLM übersetzt Anweisungen in LLM-optimierte Prompt), zerlegt komplexe Codierungsschemata in handhabbare Unteraufgaben. Das soll die Struktur und Leistung erhöhen.

-   Intransparenz, LLM als "Black Box": Classifier muss CoT Reasoning liefern, das soll Transparenz der Klassifikationsentscheidung erhöhen und Validierung und Prompt-Optimierung erleichtern

-   Bias und Validitätsbedenken: Human Intermediary für methodologische Strenge, durch kontinuierliche Verfeinerung der Prompt und Überprüfung der LLM-Begründung können Fehlinterpretationen und insbes. systematische Fehler erkannt und korrigiert werden

## Vorschlag zur Integration des Agentic Wokflow ins Tool

### Grundidee:

Tool als gesamten Arbeitsprozess der LLM-gestützten Inhaltsanalyse als mehrstufiger Ablauf. Orientiert am Agentic Workflow, und den Rollen Human Intermediary, Instructor, Classifier (optional Judge), um aktuelle Herausforderungen anzusprechen, menschliche Kontrolle zu integrieren und insbesondere die mangelnde Systematik von Prompt-Engineering anzugehen.

### Struktur:

1.  Aufgaben- und Materialdefinition (Human Intermediary)

-   Datensatz: File Input (z.B. CSV), zum Laden der Dateien

-   Kategoriensystem/Codebuch: Text Input (Beschreibung der Kategorien) oder File Input (Uploas Codebuch), der Text der Codieranweisung wird gespeichert (als Input für den Instructor)

-   Codieraufgabe: Text Input (Beschreibung der Aufgabe), ergänzt die Kategoriesystemeingabe (als Input für den Instructor) \|

2.  Instructor: Prompt-Generierung

-   LLM erstellt auf dieser Basis einen ersten Promptvorschlag für die Codierung, Anzeige des Promptvorschlages, manuelle Anpassung durch Nutzerin möglich, Speicherung und/oder Versionerung der Prompt-Versionen.

-   System-Prompt: Modus zur Prompt-Generierung mit Instruktion als "Prompt-Designer"

-   User-Input: Kategoriesystem/Codebook, Codieraufgabe, Strukturanforderung (definiert von Human Intermediary). Wird als User-Prompt dem Modell übergeben.

-   Output: Der generierte Prompt-Text (V01). Das Ergebnis wird in der Benutzeroberfläche ausgegeben und gespeichert (Versionierung).

3.  Subsample Codierung (Classifier)

-   Classifier führt Codierung eines Teils der Daten durch

-   Testsample: Auswahl einer zufälligen Stichprobe (N=?) aus dem Datensatz.

-   Prompt-Übergabe: Übergabe der aktuellsten Prompt und des Dokumentenextes an den Classifier.

-   Output-Parsing: Datenextraktion: Finale Codierung und Begründung (CoT)

-   Anzeige der Ergebnisse: Tabelle mit Originaltext, LLM-Codierung und CoT-Begründung

4.  Iterative Optimierung

-   Human Intermediary, Möglichkeit zur Beschreibung des Problems für den Instructor, Rückführung dieses Feedbacks an den Instructor, automatische Optimierung der Prompt

-   Feedback-Input: Text Input für die Problembeschreibung und Korrekturanweisung. Dies bildet den User-Input für den Instructor im Prompt-Optimierungsmodus

-   Instructor-Aufruf: Modus zur Prompt-Optimierung: Aufruf mit der letzten Prompt-Version und menschlichem Feedback, System-Prompt zur Prompt-Optimierung

-   Output: Neue, optimierte Prompt wird generiert und in der Benutzeroberfläche angezeit und als nächste Version gespeichert.

5.  Finale Codierung

-   Durchführung der Codierung des gesamten Datensatzes

-   Batch-Prozess: Button zum Ausführen des Classifiers mit der letzten Prompt über den gesamten Datensatz

-   Ergebnisspeicherung: Speichern der finalen Codierungen und aller CoT-Begründungen

6.  Optional: Judge

-   Wäre aktivierbar bei widersprüchlichen oder unsicheren Ergebnissen; Entscheidung zwischen mehreren Codierungen auf Basis der Begründungen

### Modellauswahl

**Generell aus der Literatur:**

-   Open-Source Modelle für Transparenz und Replizierbarkeit

-   Grössere Modelle führen Klassifikationsaufgaben für komplexere Konzepte besser durch

-   Für Prompt-basierte Aufgaben sind Modelle am besten geeignet, die fein abgestimmt wurden, um Anweisungen zu befolgen (instruct-Versionen)

**Für Agentic Workflow (Farjam et al.)**

-   Zusätzliche Anforderung: Konsistenz zwischen den Agenten

-   Instructor und Classifier sollten dieselbe Version des LLMs verwenden, sodass die vom Instructor generierten Anweisungen optimal auf die Fähigkeiten des Classifiers abgestimmt sind.

(+Mehrsprachigkeit?)

**Modellvorschlag HuggingFace**

meta-llama/Llama-3.1-8B-Instruct (<https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct>)

-   Instruction-tuned Textgenerierungsmodell, gut für komplexe Anweisungen/wechselnde Kategoriensysteme & wechselnde Rollen (Instructor, Classifier)

-   Englisch, unterstützt Deutsch

-   Kosten(?)

Im Free Tier sind diese vernachlässigbar. Sie werden allerdings durch Performace-Einbußen "erkauft". So gesehen fallen temporale Kosten and. Da gerade die llama Modelle alle auch lokal laufen, kann das -- je nach Hardware -- eine weitere (gerade für sozialwissenschaftliche Zwecke sehr wichtige) datenschutzrechtlich sensible Umsetzung möglich machen. Das können wir gerne weiter besprechen, sofern gewünscht.

## Fragen

-   Ist diese Integration eines Agent Workflow sinnvoll und machbar? Evtl. ohne Judge, wenn das zu viel wird (kann ich nicht so gut abschätzen)

Ja, das sollte realierbar sein. Die genaue Architektur müssen wir besprechen und erpoben. Grundlegende Hürden sehe ich aber nicht.

-   Modell: Ist ein Instruct Modell sinnvoll? Generelles Feedback zum vorgeschlagenen Modell?

Erproben würde ich das unbedingt und denke, dass es durchaus sinnvoll ist. Die Frage ist, ob es mit unseren Ressourcen performnat zusammenspielen wird. Das von Ihnen vorgeschlagene Modell finde ich gut und sehr passend. De Meta Modelle dürften dank dem offenen Ansatz generell passend sein und in diesem Zusamenhang insbesondere. Da das Modell auch Deutsch unterstützt, zumindest von der Beschreibung her, denke ich, dass wir damit arbeiten können.

### Generelle Antwort

Ich finde Ihre Konkretisierung hilfreich und zielführend. Den *Agentic Workflow* Anatz finde ich spannend und ich denke, dass er Ihrem Vorhaben einen roten Faden verleiht. Bleiben Sie dabei weietrhin kreativ-kritisch und weichen Sie bei Bedarf von den Voreshlägen für die Umsetzung -- mehr sind es im Grunde ja nicht -- gerne ab. Insgesamt freue ich mich auf Ihre Realisierung, bei der ich Sie gerne unterstütze.

## Literatur

Davidson, T., & Karell, D. (2025). Integrating Generative Artificial Intelligence into Social Science Research: Measurement, Prompting, and Simulation. Sociological Methods & Research, 54(3), 775-793. <https://doi.org/10.1177/00491241251339184>

Farjam, M., Meyer, H., & Lohkamp, M. (2025). A Practical Guide and Case Study on How to Instruct LLMs for Automated Coding During Content Analysis. Social Science Computer Review,0(0).<https://doi.org/10.1177/08944393251349541>

Mützel, Sophie, and Étienne Ollion, 'Machine Learning and the Analysis of Culture', in Christian Borch, and Juan Pablo Pardo-Guerra (eds), The Oxford Handbook of the Sociology of Machine Learning, Oxford Handbooks (2025; online edn, Oxford Academic, 20 Nov. 2023), <https://doi.org/10.1093/oxfordhb/9780197653609.013.39>

Stuhler, O., Ton, C. D., & Ollion, E. (2025). From Codebooks to Promptbooks: Extracting Information from Text with Generative Large Language Models. Sociological Methods & Research, 54(3), 794-848. <https://doi.org/10.1177/00491241251336794>

Than, N., Fan, L., Law, T., Nelson, L. K., & McCall, L. (2025). Updating “The Future of Coding”: Qualitative Coding with Generative Large Language Models. Sociological Methods & Research, 54(3), 849-888. <https://doi.org/10.1177/00491241251339188>
